{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0332efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "os.environ[\"OMP_NUM_THREADS\"]=\"1\"; os.environ[\"OPENBLAS_NUM_THREADS\"]=\"1\"; os.environ[\"MKL_NUM_THREADS\"]=\"1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import spearmanr, uniform, randint\n",
    "from pathlib import Path\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import matplotlib.pyplot as plt # [추가] 산점도를 위한 라이브러리\n",
    "\n",
    "# =========================================\n",
    "# 경로 / 상수\n",
    "# =========================================\n",
    "EDGE_FP  = 'data/마포_서대문_은평_도로망_최종_v2.csv'\n",
    "LABEL_FP = 'data/은마서_교통사고.csv'\n",
    "OUT_DIR  = 'data/xgb_outputs_calibrated'\n",
    "EDGE_OUT = str(Path(OUT_DIR, '은마서_도로_위험도_calibrated.csv'))\n",
    "METRIC_OUT = str(Path(OUT_DIR, \"test_metrics_calibrated.csv\"))\n",
    "PRED_OUT   = str(Path(OUT_DIR, \"test_predictions_calibrated.csv\"))\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 123\n",
    "N_ITER = 200\n",
    "\n",
    "# =========================================\n",
    "# 유틸 함수 (기존과 동일)\n",
    "# =========================================\n",
    "def to_pair(a, b):\n",
    "    a, b = int(a), int(b)\n",
    "    return (a, b) if a <= b else (b, a)\n",
    "\n",
    "def make_tail_weights(y, lam=5.0, p=2.0):\n",
    "    y_norm = y / max(y.max(), 1e-9)\n",
    "    weights = 1.0 + lam * np.power(y_norm, p)\n",
    "    return weights\n",
    "\n",
    "# =========================================\n",
    "# 1) 데이터 로드 및 병합 (기존과 동일)\n",
    "# =========================================\n",
    "print(\"▶ 데이터 로딩 및 병합...\")\n",
    "edges = pd.read_csv(EDGE_FP, dtype={'u': str, 'v': str})\n",
    "edges['u'] = pd.to_numeric(edges['u']); edges['v'] = pd.to_numeric(edges['v'])\n",
    "labels = pd.read_csv(LABEL_FP)\n",
    "edges['pair'] = list(map(to_pair, edges['u'], edges['v']))\n",
    "labels['pair'] = list(map(to_pair, labels['node1'], labels['node2']))\n",
    "data = edges.merge(labels[['pair', 'ratio']], on='pair', how='left')\n",
    "data['ratio'] = data['ratio'].fillna(0)\n",
    "data = data.rename(columns={'ratio': 'y'})\n",
    "data = data.groupby('pair').agg({\n",
    "    **{col: 'first' for col in edges.columns if col != 'pair'}, 'y': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# =========================================\n",
    "# 2) 데이터 분할 (8:1:1) (기존과 동일)\n",
    "# =========================================\n",
    "print(\"\\n▶ 데이터 분할 (80% train, 10% validation, 10% test)...\")\n",
    "cat_cols = [c for c in ['highway','surface'] if c in data.columns]\n",
    "num_cols = [c for c in ['oneway','bridge','tunnel','length','lanes','width'] if c in data.columns]\n",
    "feature_cols = cat_cols + num_cols\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "train_idx, holdout_idx = next(gss1.split(data, groups=data['pair']))\n",
    "train_df = data.iloc[train_idx]\n",
    "holdout_df = data.iloc[holdout_idx]\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=RANDOM_STATE)\n",
    "val_idx, test_idx = next(gss2.split(holdout_df, groups=holdout_df['pair']))\n",
    "val_df = holdout_df.iloc[val_idx]\n",
    "test_df = holdout_df.iloc[test_idx]\n",
    "print(f\"  train={len(train_df)}  validation={len(val_df)}  test={len(test_df)}\")\n",
    "\n",
    "# =========================================\n",
    "# 3) 전처리 및 가중치 생성 (기존과 동일)\n",
    "# =========================================\n",
    "print(\"\\n▶ 데이터 전처리 및 가중치 생성...\")\n",
    "pre = ColumnTransformer([\n",
    "    ('cat', Pipeline([('imp', SimpleImputer(strategy='constant')), ('ohe', OneHotEncoder(handle_unknown='ignore'))]), cat_cols),\n",
    "    ('num', Pipeline([('imp', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), num_cols)\n",
    "], remainder='drop')\n",
    "X_tr = pre.fit_transform(train_df[feature_cols])\n",
    "X_va = pre.transform(val_df[feature_cols])\n",
    "X_te = pre.transform(test_df[feature_cols])\n",
    "y_tr = train_df['y'].values\n",
    "y_va = val_df['y'].values\n",
    "y_te = test_df['y'].values\n",
    "sample_weights = make_tail_weights(y_tr)\n",
    "\n",
    "# =========================================\n",
    "# 4) RandomizedSearchCV를 이용한 최적화 (기존과 동일)\n",
    "# =========================================\n",
    "print(f\"\\n▶ RandomizedSearchCV 최적화 시작 (R2 점수 기준, 탐색 횟수: {N_ITER})...\")\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.04), 'n_estimators': randint(1500, 4000),\n",
    "    'max_depth': randint(6, 12), 'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4), 'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(1, 20), 'min_child_weight': randint(1, 10)\n",
    "}\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror', eval_metric='rmse',\n",
    "    early_stopping_rounds=80, random_state=RANDOM_STATE,\n",
    "    tree_method='hist', device='cuda'\n",
    ")\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_dist, n_iter=N_ITER, scoring='r2',\n",
    "    cv=3, verbose=2, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "fit_params = { 'sample_weight': sample_weights, 'eval_set': [(X_va, y_va)], 'verbose': False }\n",
    "random_search.fit(X_tr, y_tr, **fit_params)\n",
    "print(\"\\n최적화 종료!\")\n",
    "print(\"최적의 파라미터:\"); print(random_search.best_params_)\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# =========================================\n",
    "# 5) 캘리브레이션 모델 학습\n",
    "# =========================================\n",
    "print(\"\\n▶ 캘리브레이션 모델 학습 (Validation Set)...\")\n",
    "val_pred_raw = best_model.predict(X_va)\n",
    "calibrator = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "calibrator.fit(val_pred_raw, y_va)\n",
    "print(\"캘리브레이터 학습 완료.\")\n",
    "\n",
    "# =========================================\n",
    "# 6) 최종 모델 평가 (Test Set)\n",
    "# =========================================\n",
    "print(\"\\n▶ 최종 평가 (Test Set)...\")\n",
    "y_pred_raw = best_model.predict(X_te)\n",
    "y_pred_calibrated = calibrator.predict(y_pred_raw)\n",
    "\n",
    "r2 = r2_score(y_te, y_pred_calibrated)\n",
    "rmse = np.sqrt(mean_squared_error(y_te, y_pred_calibrated))\n",
    "mae = mean_absolute_error(y_te, y_pred_calibrated)\n",
    "spearman = spearmanr(y_te, y_pred_calibrated).correlation\n",
    "metrics = pd.Series({\"R2\": r2, \"RMSE\": rmse, \"MAE\": mae, \"Spearman\": spearman})\n",
    "print(\"Hold-out Test Set 최종 평가 결과 (캘리브레이션 적용):\")\n",
    "print(metrics.round(6))\n",
    "\n",
    "metrics.to_csv(METRIC_OUT)\n",
    "pd.DataFrame({'y_true': y_te, 'y_pred_raw': y_pred_raw, 'y_pred_calibrated': y_pred_calibrated}).to_csv(PRED_OUT, index=False)\n",
    "print(f\"\\n[SAVED] Test 평가 지표 -> {METRIC_OUT}\")\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# [추가] 7) 산점도 시각화\n",
    "# =========================================\n",
    "print(\"\\n▶ 산점도 시각화...\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# 보정 전 예측값 (회색, 반투명)\n",
    "plt.scatter(y_te, y_pred_raw, alpha=0.3, label='Before Calibration (보정 전)', color='grey', s=15)\n",
    "\n",
    "# 보정 후 예측값 (파란색)\n",
    "plt.scatter(y_te, y_pred_calibrated, alpha=0.5, label='After Calibration (보정 후)', color='blue', s=20)\n",
    "\n",
    "# 완벽한 예측선 (y=x)\n",
    "line_max = max(y_te.max(), y_pred_calibrated.max()) * 1.05\n",
    "plt.plot([0, line_max], [0, line_max], 'k--', label='Perfect Prediction (y=x)')\n",
    "\n",
    "plt.xlabel(\"Actual Risk (y_true)\")\n",
    "plt.ylabel(\"Predicted Risk (y_pred)\")\n",
    "plt.title(\"Prediction vs. Actual Risk (Before & After Calibration)\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.xlim(0, line_max)\n",
    "plt.ylim(0, line_max)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "# 그래프 저장\n",
    "plot_path = os.path.join(OUT_DIR, \"scatterplot_calibrated.png\")\n",
    "plt.savefig(plot_path, dpi=200)\n",
    "print(f\"[SAVED] 산점도 -> {plot_path}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 8) 전체 도로망 스코어링\n",
    "# =========================================\n",
    "print(\"\\n▶ 전체 도로망 위험도 스코어링...\")\n",
    "X_scoring = pre.transform(data[feature_cols])\n",
    "scoring_pred_raw = best_model.predict(X_scoring)\n",
    "scoring_pred_calibrated = calibrator.predict(scoring_pred_raw)\n",
    "\n",
    "data['risk_score'] = scoring_pred_calibrated\n",
    "output_cols = ['u', 'v', 'osmid', 'highway', 'length', 'lanes', 'risk_score']\n",
    "output_cols_exist = [c for c in output_cols if c in data.columns]\n",
    "data[output_cols_exist].to_csv(EDGE_OUT, index=False)\n",
    "print(f\"[SAVED] 전체 도로 위험도 -> {EDGE_OUT}\")\n",
    "\n",
    "# (이하 파라미터 저장 부분은 기존과 동일)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
